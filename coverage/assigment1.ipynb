{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBLEM 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "minst = fetch_openml('mnist_784', cache=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = minst.data.astype('float32')\n",
    "y = minst.target.astype('int64')\n",
    "x['target'] = y\n",
    "X = []\n",
    "for i in range(10):\n",
    "  X.append(x[x['target']==i])\n",
    "  X[i] = X[i].sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing\n",
    "# train ratio is 70%\n",
    "# test ratio is 15%\n",
    "# validation ratio is 15%\n",
    "# transform the data into a torch tensor and normalize it to be between 0 and 1\n",
    "rowRange = y.value_counts()\n",
    "train = []\n",
    "test = []\n",
    "validation = []\n",
    "trainY = []\n",
    "validationY = []\n",
    "testY = []\n",
    "\n",
    "def transform(array):\n",
    "    array[i] = array[i].to_numpy()\n",
    "    array[i] = torch.Tensor(array[i])\n",
    "    array[i] = array[i]/255\n",
    "\n",
    "def getSizes(index):\n",
    "    trainSize = int(0.7 * len(X[index]))\n",
    "    validationSize = int(0.15 * len(X[index]))\n",
    "    testSize = len(X[index]) - trainSize - validationSize\n",
    "    return trainSize, validationSize, testSize\n",
    "\n",
    "for i in range(10):\n",
    "    trainSize, validationSize, testSize = getSizes(i)\n",
    "    train.append(X[i][:trainSize])\n",
    "    validation.append(X[i][trainSize:trainSize+validationSize])\n",
    "    test.append(X[i][trainSize+validationSize:])\n",
    "\n",
    "    trainY.append(train[i]['target'].to_numpy())\n",
    "    validationY.append(validation[i]['target'].to_numpy())\n",
    "    testY.append(test[i]['target'].to_numpy())\n",
    "    # cleanup\n",
    "    del train[i]['target']\n",
    "    del validation[i]['target']\n",
    "    del test[i]['target']\n",
    "    transform(train)\n",
    "    transform(test)\n",
    "    transform(validation)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification via KNN for 2 and 3 combination\n",
    "# 2 is the positive class and 3 is the negative class\n",
    "# implement the KNN algorithm\n",
    "# use the Euclidean distance and the Manhattan distance\n",
    "# use the KNN algorithm to classify the test data\n",
    "\n",
    "# create data and label concatenation 2 and 3\n",
    "\n",
    "data = torch.cat((train[2], train[3]), 0)\n",
    "dataLabel = np.concatenate((trainY[2], trainY[3]), 0)\n",
    "validation = torch.cat((validation[2], validation[3]), 0)\n",
    "validationLabel = np.concatenate((validationY[2], validationY[3]), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 2 ANSWER (a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.34"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def norm(x,y, type):\n",
    "  if(type==\"L1\"):\n",
    "    return torch.norm(x-y, p=1, dim=1)\n",
    "  elif(type==\"L2\"):\n",
    "    return torch.norm(x-y, p=2, dim=1)\n",
    "\n",
    "def knn(data, dataLabel, validation, validationLabel, k, distance_type):\n",
    "  hitCount = 0\n",
    "  for target in range(len(validation)):\n",
    "    result = norm(data, validation[target], distance_type)\n",
    "    # get the k smallest distances\n",
    "    knn = result.topk(k, largest=False)\n",
    "    count = Counter(dataLabel[knn.indices])\n",
    "    hit = count.most_common(1)[0][0]\n",
    "    if(hit == validationLabel[target]):\n",
    "      hitCount += 1\n",
    "  return round(hitCount/len(validation)*100, 2)\n",
    "\n",
    "print(\"Problem 2 ANSWER (a)\")\n",
    "pred = knn(data, dataLabel, validation, validationLabel, 5, \"L1\")\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 b) What are the hyperparameters you can tune?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) What are the hyperparameters you can tune?\n",
    "# k, distance type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Try at least two other options for each hyperparameter. Report the performance for\n",
    "each option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem2 - (c)\n",
      "K  3\n",
      "L1  99.48\n",
      "L2  99.67\n",
      "K  5\n",
      "L1  99.34\n",
      "L2  99.43\n"
     ]
    }
   ],
   "source": [
    "# c) Try at least two other options for each hyperparameter. Report the performance for\n",
    "# each option.\n",
    "print(\"Problem 2 ANSWER (c)\")\n",
    "for k in range(3,7,2):\n",
    "    predL1 = knn(data, dataLabel, validation, validationLabel, k, \"L1\")\n",
    "    predL2 = knn(data, dataLabel, validation, validationLabel, k, \"L2\")\n",
    "    print(\"K \", k)\n",
    "    print(\"L1 (Manhatten Distance): \", predL1)\n",
    "    print(\"L2 (Euclidean Distance): \", predL2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) You can try more options if you want. What is the final test accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K  3\n",
      "L2 (Euclidean Distance):  99.48\n"
     ]
    }
   ],
   "source": [
    "# d) You can try more options if you want. What is the final test accuracy?\n",
    "predL2 = knn(data, dataLabel, validation, validationLabel, 3, \"L2\")\n",
    "print(\"K \", 3)\n",
    "print(\"L2 (Euclidean Distance): \", predL2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem #3: Multiclass Classification via k-NN [15pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Make a k-NN (k=5) and its training/validation/evaluation code to perform multiclass\n",
    "classification over all digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Make a k-NN (k=5) and its training/validation/evaluation code to perform multiclass\n",
    "# classification over all digits.\n",
    "data = torch.cat((train[0], train[1]), 0)\n",
    "dataLabel = np.concatenate((trainY[0], trainY[1]), 0)\n",
    "validation = torch.cat((validation[0], validation[1]), 0)\n",
    "validationLabel = np.concatenate((validationY[0], validationY[1]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 3 ANSWER (a)\n",
      "Multiclass KNN Accuracy:  99.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Problem 3 ANSWER (a)\")\n",
    "Pred = knn(data, dataLabel, validation, validationLabel, 5, \"L2\")\n",
    "print(\"Multiclass KNN Accuracy: \", Pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) What are the hyperparameters you can tune?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) What are the hyperparameters you can tune?\n",
    "# k, distance type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Try at least two other options for each hyperparameter. Report the performance for\n",
    "each option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 3 ANSWER (c)\n",
      "K  3\n",
      "L1 (Manhatten Distance):  99.06\n",
      "L2 (Euclidean Distance):  99.15\n",
      "K  5\n",
      "L1 (Manhatten Distance):  99.15\n",
      "L2 (Euclidean Distance):  99.2\n"
     ]
    }
   ],
   "source": [
    "# c) Try at least two other options for each hyperparameter. Report the performance for\n",
    "# each option.\n",
    "print(\"Problem 3 ANSWER (c)\")\n",
    "for k in range(3,7,2):\n",
    "    predL1 = knn(data, dataLabel, validation, validationLabel, k, \"L1\")\n",
    "    predL2 = knn(data, dataLabel, validation, validationLabel, k, \"L2\")\n",
    "    print(\"K \", k)\n",
    "    print(\"L1 (Manhatten Distance): \", predL1)\n",
    "    print(\"L2 (Euclidean Distance): \", predL2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 3 ANSWER (d)\n",
      "K  3\n",
      "Multiclass L2 (Euclidean Distance) (AUC):  99.15\n"
     ]
    }
   ],
   "source": [
    "print(\"Problem 3 ANSWER (d)\")\n",
    "# d) You can try more options if you want. What is the final test accuracy?\n",
    "predL2 = knn(data, dataLabel, validation, validationLabel, 3, \"L2\")\n",
    "print(\"K \", 3)\n",
    "print(\"Multiclass L2 (Euclidean Distance) (AUC): \", predL2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HingeLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HingeLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y, y_pred):\n",
    "        return torch.mean(torch.clamp(1 - y * y_pred, min=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing\n",
    "# train ratio is 70%\n",
    "# test ratio is 15%\n",
    "# validation ratio is 15%\n",
    "# prepare the data for training and testing the SVM\n",
    "# use only torch\n",
    "X = torch.cat((train[2],train[3]), 0)\n",
    "Y = torch.Tensor(np.concatenate((trainY[2], trainY[3]), axis=0))\n",
    "Y[Y==2] = -1\n",
    "Y[Y==3] = 1\n",
    "val = torch.cat((validation[2],validation[3]), 0)\n",
    "val_label = np.concatenate((validationY[2], validationY[3]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem4 - (b)\n",
      "Training Accuracy:  65.92\n",
      "Validation Accuracy:  83.34\n"
     ]
    }
   ],
   "source": [
    "# a) Make a SVM classifier and its training/validation/evaluation code to perform binary\n",
    "# classification between digit 2 and 3.\n",
    "# b) Train for 10 epochs with batch size 64 (1 epoch is equal to one entire passing of the\n",
    "# train set; i.e., the entire train set is used for training once).\n",
    "# c) What is the final training accuracy and validation accuracy?\n",
    "\n",
    "# ACCURACY\n",
    "def accuracy(X, Y, model):\n",
    "  hitCount = 0\n",
    "  for i in range(len(X)):\n",
    "    y_pred = model(X[i])\n",
    "    if(y_pred*Y[i]>0):\n",
    "      hitCount += 1\n",
    "  return round(hitCount/len(X)*100, 2)\n",
    "\n",
    "def SVM(X, Y, val, val_label, learning_rate, epoch, batch_size):\n",
    "  model = nn.Linear(28*28, 1)\n",
    "  optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "  criterion = HingeLoss()\n",
    "  for i in range(epoch):\n",
    "    for j in range(0, len(X), batch_size):\n",
    "      optimizer.zero_grad()\n",
    "      y_pred = model(X[j:j+batch_size])\n",
    "      loss = criterion(Y[j:j+batch_size], y_pred)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "  print(\"Training Accuracy: \", accuracy(X, Y, model))\n",
    "  print(\"Validation Accuracy: \", accuracy(val, val_label, model))\n",
    "print(\"Problem4 - (b)\")\n",
    "SVM(X, Y, val, val_label, 0.1, 10, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 4 ANSWER (C)\n",
      "train opt 1\n",
      "Training Accuracy:  64.86\n",
      "Validation Accuracy:  84.33\n",
      "train opt 2\n",
      "Training Accuracy:  66.78\n",
      "Validation Accuracy:  81.74\n",
      "train opt 3\n",
      "Training Accuracy:  68.73\n",
      "Validation Accuracy:  80.46\n",
      "problem 4 ANSWER (D)\n",
      "problem 4 ANSWER (E)\n",
      "learning rate opt 0.01, epoch 10, batch size 64\n",
      "Training Accuracy:  85.19\n",
      "Validation Accuracy:  63.47\n",
      "learning rate opt 0.01, epoch 20, batch size 64\n",
      "Training Accuracy:  66.04\n",
      "Validation Accuracy:  82.63\n",
      "learning rate opt 0.01, epoch 30, batch size 64\n",
      "Training Accuracy:  74.76\n",
      "Validation Accuracy:  73.57\n",
      "learning rate opt 0.1, epoch 10, batch size 32\n",
      "Training Accuracy:  66.24\n",
      "Validation Accuracy:  82.68\n"
     ]
    }
   ],
   "source": [
    "# c) How should we choose the number of iterations to achieve good generalization? Train\n",
    "# until you think the model has achieved good generalization\n",
    "# d) What are the hyperparameters you can tune?\n",
    "# e) Try at least two other options for each hyperparameter. Report the performance for\n",
    "# each option.\n",
    "# f) You can try more options if you want. What is the final test accuracy?\n",
    "# we should choose the number of iterations to achieve good generalization by looking at the validation accuracy and training accuracy\n",
    "print(\"Problem 4 ANSWER (C)\")\n",
    "print(\"train opt 1\")\n",
    "SVM(X, Y, val, val_label, 0.1, 10, 64)\n",
    "print(\"train opt 2\")\n",
    "SVM(X, Y, val, val_label, 0.1, 20, 64)\n",
    "print(\"train opt 3\")\n",
    "SVM(X, Y, val, val_label, 0.1, 30, 64)\n",
    "print(\"problem 4 ANSWER (D)\")\n",
    "# d) What are the hyperparameters you can tune?\n",
    "# learning rate, epoch, batch size\n",
    "print(\"problem 4 ANSWER (E)\")\n",
    "print(\"learning rate opt 0.01, epoch 10, batch size 64\")\n",
    "SVM(X, Y, val, val_label, 0.01, 10, 64)\n",
    "print(\"learning rate opt 0.01, epoch 20, batch size 64\")\n",
    "SVM(X, Y, val, val_label, 0.1, 10, 32)\n",
    "print(\"learning rate opt 0.01, epoch 30, batch size 64\")\n",
    "SVM(X, Y, val, val_label, 0.1, 10, 128)\n",
    "print(\"learning rate opt 0.1, epoch 10, batch size 32\")\n",
    "SVM(X, Y, val, val_label, 0.1, 10, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem #4: Binary Classification via soft-margin SVM [15pts]\n",
    "# had a problem running this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
